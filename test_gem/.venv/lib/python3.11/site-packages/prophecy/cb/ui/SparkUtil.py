from pyspark.sql.column import Column
from typing import TypeVar, Generic, Optional, List

# This won't work is there is alias to the column.
# use re.search('AS (\S*)', col.alias('some_alias')._jc.toString()).group(1) to get column name even with alias.
# Modify this code when that support is needed, so we can extract the alias and actual name as needed.
def extractColumnName(col: Column) -> str:
    if col is not None:
        return col._jc.toString()
    return ""
