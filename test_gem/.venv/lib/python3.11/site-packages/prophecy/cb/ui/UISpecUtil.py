from collections import OrderedDict

from prophecy.cb.server.base.ComponentBuilderBase import Diagnostic, Component, SeverityLevelEnum
from prophecy.cb.common.types import PUserDefinedType
from pyspark.sql.types import StructType, ArrayType, MapType, DataType
from typing import Optional, List
from enum import Enum
from dataclasses import dataclass, field

from prophecy.cb.ui.SparkUtil import extractColumnName
from prophecy.cb.ui.uispec import SColumnExpression, SColumn
from prophecy.cb.util import StringUtils
from prophecy.cb.util.StringUtils import isBlank

specialCharacters = {".", ":", " ", "-", "$"}


class ColumnsUsage(Enum):
    WithInputAlias = 1
    WithoutInputAlias = 2
    WithAndWithoutInputAlias = 3


class SchemaFields(Enum):
    TopLevel = 1
    LeafLevel = 2


class ColumnParts:
    def __init__(self, inputColExpression: str, portName: Optional[str], columnNamesUsed: List[str]):
        self.inputColExpression = inputColExpression
        self.portName = portName
        self.columnNamesUsed = columnNamesUsed


@dataclass
class ReturnUsedColumns:
    diagnostic: Optional[Diagnostic] = None
    schema: List[str] = field(default_factory=list)


def usedSColumns(SColumnList: List[SColumn], component: Component,
                 aliasUse: ColumnsUsage = ColumnsUsage.WithoutInputAlias) -> List[ReturnUsedColumns]:
    diagnostics = []
    newNoNoneColumnList = list(filter(lambda column: column is not None, SColumnList))
    if len(newNoNoneColumnList) != len(SColumnList):
        diagnostics.append(
            ReturnUsedColumns(Diagnostic("", f"Expression cannot be empty.", SeverityLevelEnum.Error)))
    columns = set([column for sColumn in newNoNoneColumnList for column in sColumn.usedColumns])
    for colName in columns:
        if aliasUse == ColumnsUsage.WithInputAlias:
            diagnostics.append(usedSColumnsAuxil(colName, component, portNameNeeded=True))
        elif aliasUse == ColumnsUsage.WithoutInputAlias:
            diagnostics.append(usedSColumnsAuxil(colName, component, portNameNeeded=False))
        else:
            usageWithPortAlias = usedSColumnsAuxil(colName, component, portNameNeeded=True)
            usageWithoutPortAlias = usedSColumnsAuxil(colName, component, portNameNeeded=False)
            if len(usageWithPortAlias.schema) > 0 and len(usageWithoutPortAlias.schema) > 0:
                diagnostics.append(
                    ReturnUsedColumns(Diagnostic("", f"Ambiguous column {colName} found.", SeverityLevelEnum.Error)))
            # Definite error if both left. Currently, we're just returning one of the diagnostics (the one with no alias)
            elif usageWithPortAlias.diagnostic is not None and usageWithoutPortAlias.diagnostic is not None:
                diagnostics.append(usageWithoutPortAlias)
            elif len(usageWithPortAlias.schema) > 0 or usageWithPortAlias.diagnostic is None:
                diagnostics.append(usageWithPortAlias)
            else:
                diagnostics.append(usageWithoutPortAlias)
    return diagnostics

def getColumnExprParts(columnName: str):
    isBackTickOpen = False
    tillNow = ""
    fieldNames = []
    for curr in columnName:
        if not isBackTickOpen:
            if curr == ".":
                fieldNames.append(tillNow)
                tillNow = ""
            elif curr == "`":
                isBackTickOpen = True
            else:
                tillNow = tillNow + curr
        else:
            if curr == "`":
                isBackTickOpen = False
            else:
                tillNow = tillNow + curr
    if not StringUtils.isBlank(tillNow):
        fieldNames.append(tillNow)
    return list(fieldNames)

def usedSColumnsAuxil(colName: str, component: Component, portNameNeeded: bool) -> ReturnUsedColumns:
    portAndColumns = colName.split(".", 1)  # split on first '.' character
    if portNameNeeded:
        portName = StringUtils.remove_prefix(StringUtils.remove_suffix(portAndColumns[0], "`"), "`")
        colParts = ColumnParts(colName, portName, getColumnExprParts("".join(portAndColumns[1:])))
    else:
        colParts = ColumnParts(colName, None, getColumnExprParts(colName))

    if len(colParts.columnNamesUsed) > 0 and colParts.columnNamesUsed[0].lower() == "_metadata":
        return ReturnUsedColumns(None, [])

    if portNameNeeded and len(
            list(filter(lambda input: input.slug.lower() == colParts.portName.lower(), component.ports.inputs))) == 0:
        return ReturnUsedColumns(
            Diagnostic("", f"No port name found by the name {colParts.portName} in {colParts.inputColExpression}",
                       SeverityLevelEnum.Error))
    elif len(colParts.inputColExpression.strip()) == 0:
        return ReturnUsedColumns(
            Diagnostic("", f"No column name selected from port {colParts.portName} in {colParts.inputColExpression}",
                       SeverityLevelEnum.Error))
    else:
        if portNameNeeded:
            nodePortsMatched = list(
                filter(lambda input: input.slug.lower() == colParts.portName.lower(), component.ports.inputs))
            if len(nodePortsMatched) == 0:
                return ReturnUsedColumns(
                    Diagnostic("", f"No port name found by the name {colParts.portName}", SeverityLevelEnum.Error))
            elif len(nodePortsMatched) == 1:
                nodePort = nodePortsMatched[0]
            else:
                return ReturnUsedColumns(
                    Diagnostic("", f"Ambiguous column {colParts.inputColExpression} found.", SeverityLevelEnum.Error))
        else:
            firstLevelCol = colParts.columnNamesUsed[0]
            matchingPorts = list(filter(lambda inp: inp.schema is not None and not isinstance(inp.schema, str) and len(
                list(filter(lambda field: field.name.lower() == firstLevelCol.lower(), inp.schema.fields))) != 0,
                                        component.ports.inputs))
            if len(matchingPorts) == 0:
                return ReturnUsedColumns(
                    Diagnostic("", f"No match found for column {colParts.inputColExpression}", SeverityLevelEnum.Error))
            elif len(matchingPorts) == 1:
                nodePort = matchingPorts[0]
            else:
                return ReturnUsedColumns(
                    Diagnostic("", f"Ambiguous column {colParts.inputColExpression} found.", SeverityLevelEnum.Error))
    returnUsedColum = isColPresentInGivenSchema(colParts.inputColExpression, colParts.columnNamesUsed, nodePort.schema,
                                                [])
    if returnUsedColum.diagnostic is not None:
        return returnUsedColum
    elif len(returnUsedColum.schema) > 0:
        currentSchemaValue = f"{nodePort.id}##{returnUsedColum.schema[0]}"
        finalList = [currentSchemaValue]
        for schma in returnUsedColum.schema[1:]:
            currentSchemaValue = currentSchemaValue + "." + schma
            finalList.append(currentSchemaValue)
        return ReturnUsedColumns(None, finalList)
    else:
        return ReturnUsedColumns(None, [])


def isColPresentInGivenSchema(
        inputColExpression: str,
        colPath: List[str],
        schema: Optional[StructType] = None,
        caseMatchedPathFromSchema: List[str] = None) -> ReturnUsedColumns:
    if len(colPath) == 0:
        return ReturnUsedColumns(None, caseMatchedPathFromSchema)
    if schema is None:
        return ReturnUsedColumns(
            Diagnostic("", f"{inputColExpression} is not present in schema.", SeverityLevelEnum.Error))
    headColName = colPath[0].lower()
    colNameMatchesInSchema = list(filter(lambda field: field.name.lower() == headColName, schema.fields))
    if len(colNameMatchesInSchema) == 0:
        return ReturnUsedColumns(
            Diagnostic("", f"{inputColExpression} is not present in schema.", SeverityLevelEnum.Error))
    elif len(colNameMatchesInSchema) == 1:
        subSchema = colNameMatchesInSchema[0]
        if isinstance(subSchema.dataType, StructType):
            caseMatchedPathFromSchema.append(subSchema.name)
            return isColPresentInGivenSchema(inputColExpression,
                                             colPath[1:],
                                             subSchema.dataType,
                                             caseMatchedPathFromSchema)
        elif isinstance(subSchema.dataType, ArrayType):
            if isinstance(subSchema.dataType.elementType, StructType):
                caseMatchedPathFromSchema.append(subSchema.name)
                return isColPresentInGivenSchema(
                    inputColExpression,
                    colPath[1:],
                    subSchema.dataType.elementType,
                    caseMatchedPathFromSchema)
            else:
                # Includes the case of MapType.
                caseMatchedPathFromSchema.append(subSchema.name)
                return isColPresentInGivenSchema(
                    inputColExpression,
                    colPath[1:],
                    None,
                    caseMatchedPathFromSchema)
        elif isinstance(subSchema.dataType, PUserDefinedType):
            return ReturnUsedColumns(Diagnostic("", f"PUserDefinedType not implemented", SeverityLevelEnum.Error))
        else:
            # Includes the case of MapType.
            caseMatchedPathFromSchema.append(subSchema.name)
            return isColPresentInGivenSchema(
                inputColExpression,
                colPath[1:],
                None,
                caseMatchedPathFromSchema)
    else:
        return ReturnUsedColumns(
            Diagnostic("", f"Ambiguous column {inputColExpression} found.", SeverityLevelEnum.Error))


def getColumnsToHighlight(
        columns: List[SColumnExpression],
        component: Component,
        aliasUse: ColumnsUsage = ColumnsUsage.WithoutInputAlias) -> List[str]:
    return list(set(
        [item
         for sublist in usedSColumns(list(map(lambda colExp: colExp.expression, columns)), component, aliasUse)
         for item in sublist.schema]
    ))


def getColumnsToHighlight2(
        columns: List[SColumn],
        component: Component,
        aliasUse: ColumnsUsage = ColumnsUsage.WithoutInputAlias) -> List[str]:
    return list(set(
        [item
         for sublist in usedSColumns(list(map(lambda colExp: colExp, columns)), component, aliasUse)
         for item in sublist.schema]
    ))


def getColumnsToHighlight3(
        columns: List[str],
        component: Component) -> List[str]:
    return list(set(
        [item
         for x in list(map(lambda colName: usedSColumnsAuxil(colName, component, False), columns))
         for item in x.schema]
    ))


#
# inputColumn column name selected by the user
# usedTargetNamesTokenized already consumed target names in the component
# shortest if true, this method will try to give the shortest name starting from the leaf and will keep
#
# appending the parent if a conflict occurs. The first non conflicting name. if found, is returned.
# If all the parents have been used and the conflict could still not be resolved,
# then the entire column path is returned (ie, behaviuor becomes the same as
# getTargetTokens(inputColumn, usedTargetNamesTokenized, shortest = false) .
# If false, uses the entire column path as the target name
#  A list containing column names that will be concatenated and used as the target name.
def getTargetTokens(
        inputColumn: str,
        usedTargetNamesTokenized: List[List[str]],
        shortest: bool = False) -> List[str]:
    availableTargetTokens = inputColumn.split('.')
    if shortest:
        return getTargetTokensAuxil([availableTargetTokens[-1]], availableTargetTokens[:-1], usedTargetNamesTokenized)
    else:
        return availableTargetTokens


def getTargetTokensAuxil(
        usedTargetTokens: List[str],
        remainingTargetTokens: List[str],
        usedTargetNames: List[List[str]]) -> List[str]:
    if (usedTargetTokens not in usedTargetNames) or (len(remainingTargetTokens) == 0):
        return usedTargetTokens
    else:
        usedTargetTokens.insert(0, remainingTargetTokens[-1])
        return getTargetTokensAuxil(usedTargetTokens, remainingTargetTokens[:-1], usedTargetNames)


def sanitizeColumnPart(part: str) -> str:
    shouldSanitize = False
    for character in specialCharacters:
        if character in part:
            shouldSanitize = True
            break

    if part[0].isdigit():
        shouldSanitize = True

    if shouldSanitize:
        return f"`{part}`"
    else:
        return part


def sanitizedColumn(column: str) -> str:
    finalColumnParts = list()
    for part in column.split('.'):
        finalColumnParts.append(sanitizeColumnPart(part))
    return ".".join(finalColumnParts)


def computeTargetName(
        currOption: str,
        targetColOptions: List[str],
        usedTargetNames: List[str]) -> str:
    if currOption not in usedTargetNames or len(targetColOptions) == 0:
        return currOption
    else:
        return computeTargetName(f"{targetColOptions.last}.{currOption}", targetColOptions.init, usedTargetNames)


def getAllColumns(schemaStruct: StructType, columnType: SchemaFields) -> List[str]:
    if columnType == SchemaFields.TopLevel:
        return list(map(lambda field: field.name, schemaStruct.fields))
    else:
        schemas = []
        for field in schemaStruct.fields:
            if isinstance(field.dataType, StructType):
                schemas.extend(
                    list(map(lambda retField: f"{field.name}.{retField}",
                             getAllColumns(field.dataType, columnType))))
            elif isinstance(field.dataType, MapType):
                raise NotImplemented()
            elif isinstance(field.dataType, ArrayType):
                if isinstance(field.dataType.elementType, StructType):
                    schemas.extend(list(
                        map(lambda retField: f"{field.name}.{retField}",
                            getAllColumns(field.dataType.elementType, columnType))))
                elif isinstance(field.dataType, MapType):
                    raise NotImplemented()
                else:
                    schemas.append(field.name)
            elif isinstance(field.dataType, PUserDefinedType):
                raise NotImplemented()
            else:
                schemas.append(field.name)
        return schemas


def getColumnsInSchema(portId: str, state: Component, columnType: SchemaFields) -> List[str]:
    matchedPort = list(filter(lambda nodeport: nodeport.id.lower() == portId.lower(), state.ports.inputs))
    if len(matchedPort) > 0 and matchedPort[0].schema is not None:
        return getAllColumns(matchedPort[0].schema, columnType)
    return []


def processExistingDiagnostics(*args):
    """

    :param args:
    :return:
    """
    _diagnostics = []
    if isinstance(args[0], List):
        expressions = args[0]
        propertyName = args[1]
        if len(expressions) > 0:
            if isinstance(expressions[0], SColumnExpression):
                for idx, expr in enumerate(expressions):
                    if expr.expression.diagnosticMessages is not None and len(
                            expr.expression.diagnosticMessages) > 0:
                        for message in expr.expression.diagnosticMessages:
                            _diagnostics.append(
                                Diagnostic(f"properties.{propertyName}[{idx}].expression.expression",
                                           message,
                                           SeverityLevelEnum.Error))
            elif isinstance(expressions[0], SColumn):
                for idx, expr in enumerate(expressions):
                    _diagnostics.extend(processExistingDiagnostics(expr, f"{propertyName}[{idx}]"))
    elif isinstance(args[0], SColumn):
        expression = args[0]
        propertyName = args[1]
        if expression.diagnosticMessages is not None and len(expression.diagnosticMessages) > 0:
            for message in expression.diagnosticMessages:
                _diagnostics.append(Diagnostic(f"properties.{propertyName}.expression",
                                               message,
                                               SeverityLevelEnum.Error))
    else:
        pass
    return _diagnostics


def validateExpTable(expressions: List[SColumnExpression], propertyName: str, component: Component,
                     testColumnPresence: Optional[ColumnsUsage] = None) -> List[Diagnostic]:
    _diagnostics = []
    for idx, expr in enumerate(expressions):
        d1 = processExistingDiagnostics(expr.expression, f"{propertyName}[{idx}].expression")
        if len(d1) > 0:
            _diagnostics.extend(d1)
        else:
            if len(expr.target.strip()) == 0:
                _diagnostics.append(
                    Diagnostic(f"properties.{propertyName}[{idx}].target", "Target cannot be empty.",
                               SeverityLevelEnum.Error))
            elif expr.expression is None or (len(extractColumnName(expr.expression.expression)) == 0 and isBlank(
                    expr.expression.rawExpression.strip())):
                _diagnostics.append(
                    Diagnostic(f"properties.{propertyName}[{idx}].expression.expression",
                               "Expression cannot be empty.",
                               SeverityLevelEnum.Error))
            else:
                # We're not enabling spark expression check as expr() call we're using doesn't support chaining of expressions to be passed in.
                # Drawback of this is, if our PExpression doesn't catch the expression, then only schema analyzer can throw the error.
                # if not expr.isValidSparkExpression():
                #     _diagnostics.append(Diagnostic(f"properties.{propertyName}[{idx}].expression.expression",
                #                                    f"{expr.expression.rawExpression} is not valid spark expression",
                #                                    SeverityLevelEnum.Error))
                # else:
                if testColumnPresence is not None:
                    usedColumns = usedSColumns([expr.expression], component, testColumnPresence)
                    for usedColumn in usedColumns:
                        if usedColumn.diagnostic is not None:
                            _diagnostics.append(
                                Diagnostic(f"properties.{propertyName}[{idx}].expression.expression",
                                           usedColumn.diagnostic.message,
                                           usedColumn.diagnostic.severity))

    return _diagnostics


def validateSColumn(
        scolumn: SColumn,
        fieldID: str,
        component: Component,
        testColumnPresence: Optional[ColumnsUsage] = None) -> List[Diagnostic]:
    diagnostics = []
    d0 = processExistingDiagnostics(scolumn, fieldID)

    if len(d0) > 0:
        diagnostics.extend(d0)
    else:
        if (len(scolumn.rawExpression.strip()) == 0):
            diagnostics.append(Diagnostic(
                f"properties.{fieldID}.expression",
                "Expression cannot be empty.",
                SeverityLevelEnum.Error
            ))
        else:
            # We're not enabling spark expression check as expr() call we're using doesn't support chaining of expressions to be passed in.
            # Drawback of this is, if our PExpression doesn't catch the expression, then only schema analyzer can throw the error.
            # if not scolumn.isValidSparkExpression():
            #     diagnostics.append(Diagnostic(
            #         f"properties.{fieldID}.expression",
            #         f"{scolumn.rawExpression} is not a valid spark expression.",
            #         SeverityLevelEnum.Error
            #     ))
            # else:
            if testColumnPresence is not None:
                usedColumnNames = usedSColumns([scolumn], component, testColumnPresence)
                for usedColumn in usedColumnNames:
                    if usedColumn.diagnostic is not None:
                        diagnostics.append(Diagnostic(
                            f"properties.{fieldID}.expression",
                            usedColumn.diagnostic.message,
                            usedColumn.diagnostic.severity
                        ))

    return diagnostics


@dataclass(frozen=True)
class InputPortSchema:
    slug: str
    schemaSummary: OrderedDict