from typing import Optional, List, TypeVar, Generic
from abc import abstractmethod
from pyspark.sql.types import DataType, StructType, StructField, ArrayType, MapType, NullType

class PDataType:
    @abstractmethod
    def sparkType(self) -> DataType:
        pass


class FieldMapping:
    def __init__(self, datasetId: str, datasetName : str, columnName: str, type: str):
        self.datasetId = datasetId
        self.datasetName = datasetName
        self.columnName = columnName
        self.type = type


class FieldTag:
    def __init__(self, name: str, tyoe: str):
        self.name = name
        self.type = type


class PStructFieldMd:
    def __init__(self, description: str = "", tags: List[FieldTag] = [], mappings: List[FieldMapping] = True):
        self.description = description
        self.tags = tags
        self.mappings = mappings


class PStructField:
    def __init__(self, name: str, dataType: PDataType, nullable: bool = True, metadata: PStructFieldMd = PStructFieldMd()):
        self.name = name
        self.dataType = dataType
        self.nullable = nullable
        self.metadata = metadata

    def sparkType(self) -> StructField:
        StructField(self.name, self.dataType.sparkType, self.nullable, self.metadata)


class PStructType(PDataType):
    def __init__(self, fields: List[PStructField], toExplode: bool = False):
        self.fields = fields
        self.toExplode = toExplode

    def sparkType(self) -> StructType:
        return StructType([field.sparkType() for field in self.fields])


class PArrayType(PDataType):
    def __init__(self, elementType: PDataType, containsNull: bool = False):
        self.elementType = elementType
        self.containsNull = containsNull

    def sparkType(self) -> DataType:
        return ArrayType(self.elementType.sparkType, self.containsNull)


class PMapType(PDataType):
    def __init__(self, keyType: PDataType, valueType: PDataType, valueContainsNull: bool = True):
        self.keyType = keyType
        self.valueType = valueType
        self.valueContainsNull = valueContainsNull

    def sparkType(self) -> DataType:
        return MapType(self.keyType.sparkType, self.valueType.sparkType, self.valueContainsNull)


class PUserDefinedType(PDataType):
    def __init__(self, className: str):
        self.className = className

    # Kish - TODO: This needs to be implemented
    def sparkType(self) -> DataType:
        return NullType()